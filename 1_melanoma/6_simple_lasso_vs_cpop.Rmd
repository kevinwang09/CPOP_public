---
title: "6 CPOP vs simple Lasso predictions"
author: "Kevin Wang"
date: "`r paste0('Initiated on 2022 Jan 10, compiled on ', format(Sys.time(), '%Y %b %d'))`"
output:
  html_document:
    code_folding: hide
    fig_height: 10
    fig_width: 10
    toc: yes
    number_sections: true
    toc_depth: 3
    toc_float: yes
editor_options: 
  chunk_output_type: console
---


# Summary

+ When using Lasso on the MIA-NS or MIA-Microarray data, the features selected are not identical, with many features being selected by only one dataset but not the other. 

+ This does not improve when we look at the correlation of prediction value.


```{r}
today = format(Sys.time(), "%Y_%b_%d")
cat("This file was compiled on", today)


suppressPackageStartupMessages({
  library(tidyverse)
  library(CPOP)
  library(glmnet)
  library(survival)
  library(survminer)
  library(patchwork)
  library(sva)
  library(fairness)
  library(yardstick)
})

theme_set(theme_classic(16) +
            theme(legend.position = "bottom", 
                  axis.text = element_text(colour = "black"),
                  axis.ticks = element_line(colour = "black")))
```


## data

```{r}
file_version = "2020_Apr_25"
load(paste0(
  "../data/processed_data/Melanoma4_binary_",
  file_version, ".RData"
))


load(paste0(
  "../data/processed_data/Melanoma4_survival_",
  file_version, ".RData"
))
```


```{r}
list_lratio_binary = list_raw_data_binary %>%
  purrr::map(t) %>%
  purrr::map(CPOP::pairwise_col_diff)

list_lratio_survival = list_raw_data %>%
  purrr::map(t) %>%
  purrr::map(CPOP::pairwise_col_diff)
```

## Customised functions
```{r}
join_tcga_sample_data = function(dat){
  dat %>% 
    left_join(tcga_sample_data, by = c("samples" = "sample_id")) %>% 
    dplyr::filter(naive_tumor_stage == "stageIII", !str_detect(samples, "TCGA-EE")) %>% 
    dplyr::mutate(time = time/365) %>% 
    dplyr::mutate(
    tcga_median_class = case_when(
      status == 0 & time > median(time) ~ "Good",
      status == 1 & time < median(time) ~ "Poor",
      TRUE ~ NA_character_))
}

join_sweden_sample_data = function(dat){
  dat %>% 
    left_join(sweden_sample_data, by = c("samples" = "sample_id")) %>% 
    dplyr::mutate(time = dss/365, status = dss_dead) %>% 
    dplyr::mutate(
    sweden_median_class = case_when(
      status == 0 & time > median(time) ~ "Good",
      status == 1 & time < median(time) ~ "Poor",
      TRUE ~ NA_character_))
}

eval_prediction_df = function(dat){
  cat("Predicted classes: \n")
  table(dat$pred_class)
  
  cat("KM-plots: \n")
  print(
    survminer::ggsurvplot(
      fit = survfit(Surv(time, status) ~ pred_class, 
                    data = dat), 
      data = dat, 
      break.time.by = 5,
      pval = TRUE, risk.table = "nrisk_cumevents"))
  
  surv_obj = coxph(Surv(time, status) ~ pred_class + age + gender, 
          data = dat)
  
  cat("Cox regression summary: \n")
  summary(surv_obj)
  broom::glance(surv_obj, data = dat) %>% glimpse
  
  # equal_odds(
  #   data  = dat %>% 
  #     dplyr::mutate(
  #       surv_median_class = case_when(
  #         status == 0 & time > median(time) ~ "Good",
  #         status == 1 & time < median(time) ~ "Poor",
  #         TRUE ~ NA_character_)) %>% 
  #     dplyr::filter(complete.cases(surv_median_class)),
  #   outcome = 'surv_median_class',
  #   probs   = 'pred_prob',
  #   group   = 'gender',
  #   cutoff  = 0.5)
}
```


# Cross validation on CPOP/Lasso evaluation on TCGA/Sweden based on Prediction/Resubstitution

```{r}
cv_partition = function(x, y, nfolds){
  n = length(y) ## The number of observations
  # obsNum = paste0("obs", seq_len(n))
  # rownames(x) = obsNum
  # names(y) = obsNum

  testIndex = caret::createFolds(y, k = nfolds) ## Creating test index
  trainIndex = lapply(testIndex, function(i){(1:n)[-i]}) ## The train index is mutually exclusive to the test index
  originalIndex = order(unlist(testIndex))

  testX = lapply(testIndex, function(k) {x[k, ,drop = FALSE]})
  testY = lapply(testIndex, function(k) {y[k]})
  trainX = lapply(trainIndex, function(k) x[k, ,drop = FALSE])
  trainY = lapply(trainIndex, function(k) {y[k]})

  result = list(foldNum = names(testIndex),
                testX = testX,
                testY = testY,
                trainX = trainX,
                trainY = trainY,
                originalIndex = originalIndex)
  return(result)
}

my_glmnet_pred = function(object, newx){
  if(is.null(object)){
    return(NULL)
  } else {
    features = object %>% coef %>% rownames %>% magrittr::extract(-1)
    newx = newx[, features]
    
    tibble(
      samples = rownames(newx),
      pred_prob = predict(
        object, newx = newx,
        type = "response", s = "lambda.min") %>% as.vector(),
      pred_class = predict(
        object, newx = newx,
        type = "class", s = "lambda.min") %>% as.vector())
  }
}
```


## Training

```{r}
one_cv_eval = function(){

  cv_ns = cv_partition(x = list_lratio_binary$ns,
                       y = list_binary_lassoy$ns, nfolds = 5)

  cv_array = cv_partition(x = list_lratio_binary$array,
                          y = list_binary_lassoy$array, nfolds = 5)

  list_train_cpop = tryCatch(expr = {
    purrr::pmap(
    .l = list(ns_x = cv_ns$trainX, ns_y = cv_ns$trainY,
              array_x = cv_array$trainX, array_y = cv_array$trainY),
    .f = function(ns_x, ns_y, array_x, array_y){
      CPOP::cpop_model(
        z1 = ns_x,
        z2 = array_x,
        y1 = ns_y,
        y2 = array_y,
        family = "binomial",
        nfolds = 5,
        alpha = 0.1,
        n_features = 20,
        n_iter = 50)})
  }, error = function(e){NULL}) %>% suppressWarnings()

  if(purrr::map_lgl(list_train_cpop, is.null) %>% all){return(NULL)}

  list_train_lasso = tryCatch({
    purrr::pmap(
    .l = list(ns_x = cv_ns$trainX, ns_y = cv_ns$trainY,
              array_x = cv_array$trainX, array_y = cv_array$trainY),
    .f = function(ns_x, ns_y, array_x, array_y){
      lasso = glmnet::cv.glmnet(
        x = rbind(ns_x, array_x),
        y = c(ns_y, array_y),
        family = "binomial",
        nfolds = 5,
        alpha = 1)

      lasso_features = lasso %>% CPOP::get_lasso_coef() %>% rownames %>% magrittr::extract(-1)

      lasso_features_ridge = glmnet::cv.glmnet(
        x = rbind(ns_x, array_x)[, lasso_features],
        y = c(ns_y, array_y),
        family = "binomial",
        nfolds = 5,
        alpha = 0)

      return(lst(lasso_features, lasso_features_ridge))
    })
  }, error = function(e){NULL})

  list_train_lasso_features = purrr::map(list_train_lasso, "lasso_features")
  if(any(sapply(list_train_lasso_features, length)) == 0){return(NULL)}
  list_train_lasso_features_ridge = purrr::map(list_train_lasso, "lasso_features_ridge")
  ################# CPOP - cross platform ############################
  cpop_pred_tcga = purrr::map_dfr(
    .x = list_train_cpop,
    ~ CPOP::predict_cpop(
      cpop_result = .x,
      newz = list_lratio_binary$tcga, s = "lambda.min"),
    .id = "fold_num") %>%
    dplyr::select(fold_num, samples,
                  cpop_pred_tcga_prob = cpop_model_avg_prob,
                  cpop_pred_tcga_class = cpop_model_avg_class)

  cpop_pred_sweden = purrr::map_dfr(
    .x = list_train_cpop,
    ~ CPOP::predict_cpop(
      cpop_result = .x,
      newz = list_lratio_binary$sweden, s = "lambda.min"),
    .id = "fold_num") %>%
    dplyr::select(fold_num, samples,
                  cpop_pred_sweden_prob = cpop_model_avg_prob,
                  cpop_pred_sweden_class = cpop_model_avg_class)
  ################# Lasso - cross platform ############################
  lasso_pred_tcga = purrr::map_dfr(
    .x = list_train_lasso_features_ridge,
    .f = ~ my_glmnet_pred(.x, newx = list_lratio_binary$tcga),
    .id = "fold_num") %>%
    dplyr::select(fold_num, samples,
                  lasso_pred_tcga_prob = pred_prob,
                  lasso_pred_tcga_class = pred_class)

  lasso_pred_sweden = purrr::map_dfr(
    .x = list_train_lasso_features_ridge,
    .f = ~ my_glmnet_pred(.x, newx = list_lratio_binary$sweden),
    .id = "fold_num") %>%
     dplyr::select(fold_num, samples,
                  lasso_pred_sweden_prob = pred_prob,
                  lasso_pred_sweden_class = pred_class)
  ################# CPOP - resub ridge using CPOP features ############################
  list_train_cpop_features = purrr::map(list_train_cpop, "feature")
  list_cpop_resub_tcga = purrr::map(
    .x = list_train_cpop_features,
    .f = ~ {
      if(length(.x) == 0){return(NULL)} else{
        glmnet::cv.glmnet(
          x = list_lratio_binary$tcga[, .x],
          y = list_binary_lassoy$tcga,
          family = "binomial",
          nfolds = 5,
          alpha = 0)}})

  cpop_resub_tcga = purrr::map_dfr(
    .x = list_cpop_resub_tcga,
    .f = ~ my_glmnet_pred(.x, newx = list_lratio_binary$tcga),
    .id = "fold_num") %>%
    dplyr::select(fold_num, samples,
                  cpop_resub_tcga_prob = pred_prob,
                  cpop_resub_tcga_class = pred_class)

  list_cpop_resub_sweden = purrr::map(
    .x = list_train_cpop_features,
    .f = ~ {
      if(length(.x) == 0){return(NULL)} else{
        glmnet::cv.glmnet(
          x = list_lratio_binary$sweden[, .x],
          y = list_binary_lassoy$sweden,
          family = "binomial",
          nfolds = 5,
          alpha = 0)}
    })
  
  cpop_resub_sweden = purrr::map_dfr(
    .x = list_cpop_resub_sweden,
    .f = ~ my_glmnet_pred(.x, newx = list_lratio_binary$sweden),
    .id = "fold_num") %>%
    dplyr::select(fold_num, samples,
                  cpop_resub_sweden_prob = pred_prob,
                  cpop_resub_sweden_class = pred_class)
  ################# Lasso - resub ridge using Lasso features ############################
  list_lasso_resub_tcga = purrr::map(
    .x = list_train_lasso_features,
    .f = ~ glmnet::cv.glmnet(
      x = list_lratio_binary$tcga[, .x],
      y = list_binary_lassoy$tcga,
      family = "binomial",
      nfolds = 5,
      alpha = 0))

  lasso_resub_tcga = purrr::map_dfr(
    .x = list_lasso_resub_tcga,
    .f = ~ my_glmnet_pred(.x, newx = list_lratio_binary$tcga),
    .id = "fold_num") %>%
    dplyr::select(fold_num, samples,
                  lasso_resub_tcga_prob = pred_prob,
                  lasso_resub_tcga_class = pred_class)


  list_lasso_resub_sweden = purrr::map(
    .x = list_train_cpop_features,
    .f = ~ {
      if(length(.x) == 0){return(NULL)} else{
        glmnet::cv.glmnet(
          x = list_lratio_binary$sweden[, .x],
          y = list_binary_lassoy$sweden,
          family = "binomial",
          nfolds = 5,
          alpha = 0)
      }})

  lasso_resub_sweden = purrr::map_dfr(
    .x = list_lasso_resub_sweden,
    .f = ~ my_glmnet_pred(.x, newx = list_lratio_binary$sweden),
    .id = "fold_num") %>%
    dplyr::select(fold_num, samples,
                  lasso_resub_sweden_prob = pred_prob,
                  lasso_resub_sweden_class = pred_class)

  tcga_pred_tbl = cpop_pred_tcga %>%
    left_join(lasso_pred_tcga, by = c("samples", "fold_num")) %>%
    left_join(cpop_resub_tcga, by = c("samples", "fold_num")) %>%
    left_join(lasso_resub_tcga, by = c("samples", "fold_num"))

  sweden_pred_tbl = cpop_pred_sweden %>%
    left_join(lasso_pred_sweden, by = c("samples", "fold_num")) %>%
    left_join(cpop_resub_sweden, by = c("samples", "fold_num")) %>%
    left_join(lasso_resub_sweden, by = c("samples", "fold_num"))

  return(lst(tcga_pred_tbl, sweden_pred_tbl))
}
```

```{r, eval = FALSE}
n_cv = 100
set.seed(202201)
library(furrr)
plan(multisession, workers = 6)

list_cv_eval = furrr::future_map(.x = 1:n_cv,
                                 .f = ~ one_cv_eval(), .progress = TRUE)

# list_cv_eval = vector("list", n_cv)

# for(i in 1:n_cv){
#   print(i)
#   list_cv_eval[[i]] = one_cv_eval()
# }

saveRDS(list_cv_eval, file = paste0("../data/processed_data/cv_evaluation_cpop_lasso_pred_and_resub", today, ".rds"))
```

```{r}
list_cv_eval = readRDS("../data/processed_data/cv_evaluation_cpop_lasso_pred_and_resub2022_Feb_07.rds")

length(list_cv_eval)
```

# TCGA evaluation

## Concordance

```{r}
tcga_eval_df = list_cv_eval %>% 
  purrr::map("tcga_pred_tbl") %>% 
  bind_rows(.id = "exp_num") %>% 
  join_tcga_sample_data() %>% 
  dplyr::mutate(
    across(.cols = contains("_class"),
           .fns = ~ factor(x = .x, levels = c("Good", "Poor")))
    )

tcga_eval_df_concord = tcga_eval_df %>% 
  group_by(exp_num) %>% 
  dplyr::summarise(
    cpop_corr = cor(cpop_pred_tcga_prob, cpop_resub_tcga_prob),
    lasso_corr = cor(lasso_pred_tcga_prob, lasso_resub_tcga_prob),
    cpop_concord = ccc_vec(cpop_pred_tcga_prob, cpop_resub_tcga_prob),
    lasso_concord = ccc_vec(lasso_pred_tcga_prob, lasso_resub_tcga_prob))

tcga_eval_df_concord %>% 
  pivot_longer(
    cols = -exp_num,
    names_to = c("model", "metric"),
    values_to = "value",
    names_sep = "_") %>% 
  ggplot(aes(x = model, y = value)) +
  geom_boxplot() +
  facet_wrap(~metric)
```

## Classification

```{r}
ms = yardstick::metric_set(
  yardstick::spec, 
  yardstick::sens,
  yardstick::f_meas,
  yardstick::bal_accuracy)

tcga_eval_df_class = tcga_eval_df %>% 
  group_by(exp_num) %>% 
  tidyr::nest() %>% 
  dplyr::mutate(
    cpop_pred_ms = purrr::map(
      .x = data, 
      .f = ~ ms(data = .x,
                truth = tcga_median_class, 
                estimate = cpop_pred_tcga_class)),
    lasso_pred_ms = purrr::map(
      .x = data, 
      .f = ~ ms(data = .x,
                truth = tcga_median_class, 
                estimate = lasso_pred_tcga_class)),
    cpop_resub_ms = purrr::map(
      .x = data, 
      .f = ~ ms(data = .x,
                truth = tcga_median_class, 
                estimate = cpop_resub_tcga_class)),
    lasso_resub_ms = purrr::map(
      .x = data, 
      .f = ~ ms(data = .x,
                truth = tcga_median_class, 
                estimate = lasso_resub_tcga_class))) %>% 
  dplyr::select(-data)
```

```{r}
tcga_eval_df_class %>% 
  pivot_longer(cols = -exp_num) %>% 
    tidyr::unnest(value) %>% 
  ggplot(aes(x = name, y = .estimate)) +
  geom_boxplot() +
  facet_wrap(~.metric, scales = "free_y")
```

# sweden evaluation

## Concordance

```{r}
sweden_eval_df = list_cv_eval %>% 
  purrr::map("sweden_pred_tbl") %>% 
  bind_rows(.id = "exp_num") %>% 
  join_sweden_sample_data() %>% 
  dplyr::mutate(
    across(.cols = contains("_class"),
           .fns = ~ factor(x = .x, levels = c("Good", "Poor")))
    )

sweden_eval_df_concord = sweden_eval_df %>% 
  group_by(exp_num) %>% 
  dplyr::summarise(
    cpop_corr = cor(cpop_pred_sweden_prob, cpop_resub_sweden_prob),
    lasso_corr = cor(lasso_pred_sweden_prob, lasso_resub_sweden_prob),
    cpop_concord = ccc_vec(cpop_pred_sweden_prob, cpop_resub_sweden_prob),
    lasso_concord = ccc_vec(lasso_pred_sweden_prob, lasso_resub_sweden_prob))

sweden_eval_df_concord %>% 
  pivot_longer(
    cols = -exp_num,
    names_to = c("model", "metric"),
    values_to = "value",
    names_sep = "_") %>% 
  ggplot(aes(x = model, y = value)) +
  geom_boxplot() +
  facet_wrap(~metric)
```

## Classification

```{r}
ms = yardstick::metric_set(
  yardstick::spec, 
  yardstick::sens,
  yardstick::f_meas,
  yardstick::bal_accuracy)

sweden_eval_df_class = sweden_eval_df %>% 
  group_by(exp_num) %>% 
  tidyr::nest() %>% 
  dplyr::mutate(
    cpop_pred_ms = purrr::map(
      .x = data, 
      .f = ~ ms(data = .x,
                truth = sweden_median_class, 
                estimate = cpop_pred_sweden_class)),
    lasso_pred_ms = purrr::map(
      .x = data, 
      .f = ~ ms(data = .x,
                truth = sweden_median_class, 
                estimate = lasso_pred_sweden_class)),
    cpop_resub_ms = purrr::map(
      .x = data, 
      .f = ~ ms(data = .x,
                truth = sweden_median_class, 
                estimate = cpop_resub_sweden_class)),
    lasso_resub_ms = purrr::map(
      .x = data, 
      .f = ~ ms(data = .x,
                truth = sweden_median_class, 
                estimate = lasso_resub_sweden_class))) %>% 
  dplyr::select(-data)
```

```{r}
sweden_eval_df_class %>% 
  pivot_longer(cols = -exp_num) %>% 
    tidyr::unnest(value) %>% 
  ggplot(aes(x = name, y = .estimate)) +
  geom_boxplot() +
  facet_wrap(~.metric, scales = "free_y")
```
